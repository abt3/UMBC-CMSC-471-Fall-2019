{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <h1><center>CMSC 471: Introduction to Artificial Intelligence</center></h1>\n",
    "\n",
    "<center><img src=\"img/title.jpeg\" align=\"center\"/></center>\n",
    "\n",
    "\n",
    "<h3 style=\"color:blue;\"><center>Instructor: Fereydoon Vafaei</center></h3>\n",
    "\n",
    "\n",
    "<h5 style=\"color:purple;\"><center>Chapter 3 \"Informed Search - Heuristic Functions\"<br></center></h5>\n",
    "\n",
    "<center><img src=\"img/UMBC_logo.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Agenda</center></h1>\n",
    "\n",
    "- <b>Q/A:</b> Are there any questions?\n",
    "- <b> Announcements, updates and reminders</b> \n",
    "- <b> Chapter 3: Heuristic Functions</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>Announcements, updates and reminders:</b>\n",
    "    - [Schedule](https://www.csee.umbc.edu/courses/undergraduate/471/fall19/01/schedule.html) updated until <font color=\"green\">midterm exam</font> which is scheduled for **Thursday October 31st**\n",
    "    - Midterm review session: **Tuesday October 29**\n",
    "    - Quiz 4 release date: Tue Sep 24, Due Tue Oct 1.\n",
    "    - Quiz 3 Due Fri Sep 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Assignment 1 \"Uninformed Search\"](https://nbviewer.jupyter.org/github/fereydoonvafaei/UMBC-CMSC-471-Fall-2019/blob/master/Assignment-1/Assignment-1.0.ipynb) Due: Thu Sep 26 11:59PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - Schedule and reading assignments for Week 4 (Sep 16-22):\n",
    "    Chapter 4 \"Beyond Classical Search\".\n",
    "    - Schedule and reading assignments for next week - Week 5 (Sep 23-29):\n",
    "    Chapter 5 \"Adversarial Search\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Measuring Problem Solving Performance</center></h1>\n",
    "\n",
    "- <b>Completeness</b> Is the algorithm guaranteed to find a solution when there is one?\n",
    "\n",
    "- <b>Optimality</b> Does the strategy find the optimal solution? Lowest path cost among all solutions.\n",
    "\n",
    "- <b>Time Complexity</b> How long does it take to find a solution?\n",
    "\n",
    "- <b>Space Complexity</b> How much memory is needed to perform the search? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: DFS Modifications: Depth-Limited Search</center></h1>\n",
    "\n",
    "- <b>Completeness?</b> No, if $l < d$ $l$: limit, $d$: the depth of the shallowest solution.\n",
    "- <b>Optimality?</b> No, if $l > d$ $l$: limit, $d$: the depth of the shallowest solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Iterative Deepening DFS</center></h1>\n",
    "\n",
    "<img src=\"img/iterative-dfs.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Iterative Deepening DFS</center></h1>\n",
    "\n",
    "- <b>Completeness?</b> Yes, if b is finite.\n",
    "- <b>Optimality?</b> Yes, if the path cost is a nondecreasing function of the depth of the node.\n",
    "- <b>Time Complexity?</b> $O(b^d)$ b: branching factor, d: the depth of the shallowest solution.\n",
    "\n",
    "- <b>Space Complexity?</b> $O(bd)$ b: branching factor, d: the depth of the shallowest solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Bidirectional Search</center></h1>\n",
    "If, and this is a big if, every action in a search problem has a known\n",
    "inverse action allowing search to go backwards, then an $O(b^d)$\n",
    "search can be reduced to two $O(b^{d/2})$ searches by iteratively, or\n",
    "simultaneously in parallel, searching forward from the start state and\n",
    "searching backwards from the goal state.  This also assumes there is\n",
    "one goal state, or a finite number of goal states.\n",
    "<img src=\"img/bidirectional.png\" align=\"center\"/>\n",
    "From Russel&Norvig Textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uninformed Search Summary</center></h1>\n",
    "\n",
    ">This table is from page 91 of our texbook.  Here $b$ is the branching factor, $d$ is the depth of the shallowest solution, $m$ is the maximum depth of the search tree, and $l$ is the depth limit. \n",
    "\n",
    "|  Criterion  |  Breadth-First  |  Depth-First  |  Depth-Limited  |  Iterative-Deepening  |  Bidirectional  \n",
    "| :-: | :-: | :-: | :-: | :-: | :-:\n",
    "|  Complete?  |  Yes  |  No  |  No  |  Yes  |  Yes  |\n",
    "|  Optimal?  |  Yes  |  No  |  No  |  Yes  |  Yes  |\n",
    "|  Time  |  $O(b^d)$  |  $O(b^m)$  |  $O(b^l)$  |  $O(b^d)$  |  $O(b^{d/2})$  |\n",
    "|  Space  |  $O(b^d)$  |  $O(bm)$  |  $O(bl)$  |  $O(bd)$  |  $O(b^{d/2})$  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uninformed Search Summary</center></h1>\n",
    "\n",
    "Our textbook authors say:\n",
    "\n",
    "> \"In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known.\"\n",
    "\n",
    "[Watch this short video](https://www.youtube.com/watch?v=EnX8cQPiB1M) by [Richard Korf - UCLA](https://scholar.google.com/citations?user=LsuWoRoAAAAJ&hl=en) one of the developers of iterative deepening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Also from Session 5: Informed Search</center></h1>\n",
    "\n",
    "- Uses problem-specific knowledge beyond the definition of the problem itself.\n",
    "- <b>Best-first search</b> A node is selected for expansion based on an evaluation function $f(n)$\n",
    "- <b>Heuristic function $h(n)$</b> estimated cost of the cheapest path from the state at node n to a goal state - this is non-negative and problem specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Informed Search</center></h1>\n",
    "\n",
    "Also known as <font color=\"blue\">heuristic</font> search, because the search is informed by an\n",
    "estimate of the total path cost through each node, and the next\n",
    "unexpanded node with the lowest estimated cost is expanded next. \n",
    "\n",
    "    At some intermediate node, the \n",
    "      estimated cost of the solution path =\n",
    "          the sum of the step costs so far from the start node to this node\n",
    "             +\n",
    "          an estimate of the sum of the remaining step costs to a goal\n",
    "\n",
    "Let's label these as\n",
    "\n",
    "   * $f(n) =$ estimated cost of the solution path through node $n$\n",
    "   * $g(n) =$ the sum of the step costs so far from the start node to this node\n",
    "   * $h(n) =$ an estimate of the sum of the remaining step costs to a goal\n",
    "\n",
    "<font color=\"blue\">*heuristic function*</font>: $h(n) =$ estimated cost of the cheapest path from state at node $n$ to a goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uniform Cost Search</center></h1>\n",
    "\n",
    "-  It's <font color=\"blue\"><b>Uninformed Search</b></font>. No Heuristic!\n",
    "- Expand the node $n$ with the lowest path cost.\n",
    "- $f(n) = g(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Greedy Best-first Search</center></h1>\n",
    "\n",
    "- Expand the node that is closest to the goal.\n",
    "- $f(n) = h(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "- Expand the node that has the minimum value of $f(n)$\n",
    "- $f(n) = g(n) + h(n)$\n",
    "- $g(n)$ the cost from the start state to the current node\n",
    "- $h(n)$ the estimated cost from the current node to the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "<img src=\"img/astar1.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "<img src=\"img/astar2.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Admissible Heuristic Function</center></h1>\n",
    "\n",
    "- An <font color=\"blue\"><b>admissible heuristic</b></font> is one that **never overestimates** the cost of the minimum cost path from a node to the goal node.  So, a heuristic is specific to a particular state space, and also to a particular goal state in that state space.  It must be <font color=\"blue\"><b>admissible</b></font> for all states in that search space.\n",
    "\n",
    "$$\\forall\\, node\\,n, h(n) \\le h^*(n)$$\n",
    "> where $h^*(n)$ is the true actual (minimal) cost from $n$ to goal\n",
    "\n",
    "<br>\n",
    "\n",
    "- To help remember whether an admissible heuristic \"never overestimates\" or \"never underestimates\", just remember that an <font color=\"blue\"><b>admissible heuristic is too optimistic</b></font>.  It will lead $A^*$ to search paths that turn out to be more costly that the optimal path.  It will not prevent  $A^*$  from expanding a node that is on the optimal path by producing a heuristic $h$ value that is too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Consistent Heuristic Function</center></h1>\n",
    "\n",
    "- A stronger requirement on a heuristic is that it is <font color=\"blue\"><b>consistent</b></font>, sometimes called **monotonic**.  A heuristic $h$ is consistent if its value is nondecreasing along a path. Mathematically, a heuristic $h$ is consistent if for every node $n$ of a parent node $p$,\n",
    "\n",
    "$$h(p) \\le h(n) + \\mathrm{stepcost}(p,n)$$\n",
    "\n",
    "- Every consistent heuristic must be admissible. One way of showing a heuristic is consistent is proving it is admissible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> <font color=\"blue\">Active Learning</font>: A* Search Exercise</center></h1>\n",
    "\n",
    ">Solve [this A* search problem](astarexercise.pdf). Then you should exchange your paper with one of your peers to be graded by each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Optimality of A*</center></h1>\n",
    "\n",
    "- Greedy Best First Search is neither complete nor optimal.\n",
    "\n",
    "- $A^*$ is complete (mathematical proof exists but not required for the exam).\n",
    "\n",
    "- The tree-search version of A* is optimal if $h(n)$ is admissible, while the graph-version is optimal if $h(n)$ is consistent (mathematical proof in the textbook - but not required).\n",
    "\n",
    "-  $A^*$ has a high space complexity. It runs out of memory pretty quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Memory-Bounded Heuristic Search</center></h1>\n",
    "\n",
    "- No other algorithm that extends search paths from the start node and uses the same heuristic information will expand fewer nodes that $A^*$.\n",
    "\n",
    "\n",
    "- However, maintaining the list of unexpanded frontier nodes can quickly consume all storage.  This is why sometimes the  modified versions of $A^*$ are used.\n",
    "\n",
    "\n",
    "- For instance, Recursive-best-first-search **RBFS** strategy is throwing away and regenerating nodes and reduces the maximum number of nodes stored at any point of the algorithm.  Its space complexity is linear in the depth of the deepest optimal solution. Its time complexity is hard to characterize as it depends on the accuracy of the heuristic function.\n",
    "\n",
    "\n",
    "- RBFS throws away too many nodes to be as efficient in time as it can be.  Alternatives include the simplified memory-bounded A\\*, SM$A^*$, algorithm.  SM$A^*$ proceeds like a graph-based search maintaining the unexplored frontier list.  When it runs out of memory, it deletes the node with the worst $f$ value and backs that value up to the deleted node's parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Memory-Bounded Heuristic Search</center></h1>\n",
    "\n",
    "- Iterative Deepening $A^*$ (ID$A^*$) - uses f-cost, i.e. $(g+h)$ rather than the depth.\n",
    "\n",
    "\n",
    "- Recursive Best First Search (RBFS) - uses only linear space with a DFS strategy with a f-limit. Once the current node exceeds the limit, the recursion unwinds back to the alternative path and replaces the f-value of each node on the path with the best f-value of its children.\n",
    "\n",
    "\n",
    "- Simplified MA* (SMA*) - like $A^*$ expands the best leaf until memory is full, then drops the worst leaf node, also backs up the value of the forgotten node to its parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Summary of Chapter 3</center></h1>\n",
    "\n",
    "- Search environment characteristics: Observable, Known, Discrete, Deterministic.\n",
    "\n",
    "\n",
    "- <font color=\"blue\">Uninfirmed Search</font>: BFS, Uniform-Cost Search, DFS, Depth-limited Search, Iterative Deepening Search, Bidirectional Search .\n",
    "\n",
    "\n",
    "- <font color=\"blue\">Infirmed Search</font>: Greedy Best First Search, $A^*$ Search, ID$A^*$, RBFS, SM$A^*$.\n",
    "\n",
    "\n",
    "- Search algorithms studied so far are designed to explore the search space systematically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we proceed to Chapter 4, watch this short video:\n",
    "https://www.linkedin.com/feed/update/urn:li:activity:6580049413157240833/  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

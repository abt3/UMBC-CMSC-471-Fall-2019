{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### <h1><center>CMSC 471: Introduction to Artificial Intelligence</center></h1>\n",
    "\n",
    "<center><img src=\"img/title.jpeg\" align=\"center\"/></center>\n",
    "\n",
    "\n",
    "<h3 style=\"color:blue;\"><center>Instructor: Fereydoon \"Fred\" Vafaei</center></h3>\n",
    "\n",
    "\n",
    "<h5 style=\"color:purple;\"><center>Session 7: September 19, 2019 - Chapter 3 \"Heuristic Functions\"<br>Chapter 4 \"Local Search and Optimization\"</center></h5>\n",
    "\n",
    "<center><img src=\"img/UMBC_logo.png\" align=\"center\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Agenda</center></h1>\n",
    "\n",
    "- <b>Q/A:</b> Are there any questions?\n",
    "- <b> Announcements, updates and reminders</b> \n",
    "- <b> Chapter 3: Heuristic Functions</b>\n",
    "- <b> Chapter 4: Local Search and Optimization</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>Announcements, updates and reminders:</b>\n",
    "    - [Schedule](https://www.csee.umbc.edu/courses/undergraduate/471/fall19/01/schedule.html) updated until <font color=\"green\">midterm exam</font> which is scheduled for **Thursday October 31st**\n",
    "    - Midterm review session: **Tuesday October 29**\n",
    "    - Quiz 4 release date: Thu Sep 19, Due Thu Sep 26.\n",
    "    - Quiz 3 Due Fri Sep 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [Assignment 1 \"Uninformed Search\"](https://nbviewer.jupyter.org/github/fereydoonvafaei/UMBC-CMSC-471-Fall-2019/blob/master/Assignment-1/Assignment-1.0.ipynb) Due: Thu Sep 26 11:59PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "    - Schedule and reading assignments for this week (Sep 16-22):\n",
    "    Chapter 4 \"Beyond Classical Search\".\n",
    "    - Schedule and reading assignments for next week (Sep 23-29):\n",
    "    Chapter 5 \"Adversarial Search\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Measuring Problem Solving Performance</center></h1>\n",
    "\n",
    "- <b>Completeness</b> Is the algorithm guaranteed to find a solution when there is one?\n",
    "\n",
    "- <b>Optimality</b> Does the strategy find the optimal solution? Lowest path cost among all solutions.\n",
    "\n",
    "- <b>Time Complexity</b> How long does it take to find a solution?\n",
    "\n",
    "- <b>Space Complexity</b> How much memory is needed to perform the search? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: DFS Modifications: Depth-Limited Search</center></h1>\n",
    "\n",
    "- <b>Completeness?</b> No, if $l < d$ $l$: limit, $d$: the depth of the shallowest solution.\n",
    "- <b>Optimality?</b> No, if $l > d$ $l$: limit, $d$: the depth of the shallowest solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Iterative Deepening DFS</center></h1>\n",
    "\n",
    "<img src=\"img/iterative-dfs.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Session 5 Review: Iterative Deepening DFS</center></h1>\n",
    "\n",
    "- <b>Completeness?</b> Yes, if b is finite.\n",
    "- <b>Optimality?</b> Yes, if the path cost is a nondecreasing function of the depth of the node.\n",
    "- <b>Time Complexity?</b> $O(b^d)$ b: branching factor, d: the depth of the shallowest solution.\n",
    "\n",
    "- <b>Space Complexity?</b> $O(bd)$ b: branching factor, d: the depth of the shallowest solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Bidirectional Search</center></h1>\n",
    "If, and this is a big if, every action in a search problem has a known\n",
    "inverse action allowing search to go backwards, then an $O(b^d)$\n",
    "search can be reduced to two $O(b^{d/2})$ searches by iteratively, or\n",
    "simultaneously in parallel, searching forward from the start state and\n",
    "searching backwards from the goal state.  This also assumes there is\n",
    "one goal state, or a finite number of goal states.\n",
    "<img src=\"img/bidirectional.png\" align=\"center\"/>\n",
    "From Russel&Norvig Textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uninformed Search Summary</center></h1>\n",
    "\n",
    ">This table is from page 91 of our texbook.  Here $b$ is the branching factor, $d$ is the depth of the shallowest solution, $m$ is the maximum depth of the search tree, and $l$ is the depth limit. \n",
    "\n",
    "|  Criterion  |  Breadth-First  |  Depth-First  |  Depth-Limited  |  Iterative-Deepening  |  Bidirectional  \n",
    "| :-: | :-: | :-: | :-: | :-: | :-:\n",
    "|  Complete?  |  Yes  |  No  |  No  |  Yes  |  Yes  |\n",
    "|  Optimal?  |  Yes  |  No  |  No  |  Yes  |  Yes  |\n",
    "|  Time  |  $O(b^d)$  |  $O(b^m)$  |  $O(b^l)$  |  $O(b^d)$  |  $O(b^{d/2})$  |\n",
    "|  Space  |  $O(b^d)$  |  $O(bm)$  |  $O(bl)$  |  $O(bd)$  |  $O(b^{d/2})$  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uninformed Search Summary</center></h1>\n",
    "\n",
    "Our textbook authors say:\n",
    "\n",
    "> \"In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known.\"\n",
    "\n",
    "[Watch this short video](https://www.youtube.com/watch?v=EnX8cQPiB1M) by [Richard Korf - UCLA](https://scholar.google.com/citations?user=LsuWoRoAAAAJ&hl=en) one of the developers of iterative deepening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Also from Session 5: Informed Search</center></h1>\n",
    "\n",
    "- Uses problem-specific knowledge beyond the definition of the problem itself.\n",
    "- <b>Best-first search</b> A node is selected for expansion based on an evaluation function $f(n)$\n",
    "- <b>Heuristic function $h(n)$</b> estimated cost of the cheapest path from the state at node n to a goal state - this is non-negative and problem specific."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Informed Search</center></h1>\n",
    "\n",
    "Also known as <font color=\"blue\">heuristic</font> search, because the search is informed by an\n",
    "estimate of the total path cost through each node, and the next\n",
    "unexpanded node with the lowest estimated cost is expanded next. \n",
    "\n",
    "    At some intermediate node, the \n",
    "      estimated cost of the solution path =\n",
    "          the sum of the step costs so far from the start node to this node\n",
    "             +\n",
    "          an estimate of the sum of the remaining step costs to a goal\n",
    "\n",
    "Let's label these as\n",
    "\n",
    "   * $f(n) =$ estimated cost of the solution path through node $n$\n",
    "   * $g(n) =$ the sum of the step costs so far from the start node to this node\n",
    "   * $h(n) =$ an estimate of the sum of the remaining step costs to a goal\n",
    "\n",
    "<font color=\"blue\">*heuristic function*</font>: $h(n) =$ estimated cost of the cheapest path from state at node $n$ to a goal state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Uniform Cost Search</center></h1>\n",
    "\n",
    "-  It's <font color=\"blue\"><b>Uninformed Search</b></font>. No Heuristic!\n",
    "- Expand the node $n$ with the lowest path cost.\n",
    "- $f(n) = g(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Greedy Best-first Search</center></h1>\n",
    "\n",
    "- Expand the node that is closest to the goal.\n",
    "- $f(n) = h(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "- Expand the node that has the minimum value of $f(n)$\n",
    "- $f(n) = g(n) + h(n)$\n",
    "- $g(n)$ the cost from the start state to the current node\n",
    "- $h(n)$ the estimated cost from the current node to the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "<img src=\"img/astar1.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>A* Search</center></h1>\n",
    "\n",
    "<img src=\"img/astar2.png\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Admissible Heuristic Function</center></h1>\n",
    "\n",
    "- An <font color=\"blue\"><b>**admissible heuristic**</font> is one that **never overestimates** the cost of the minimum cost path from a node to the goal node.  So, a heuristic is specific to a particular state space, and also to a particular goal state in that state space.  It must be <font color=\"blue\">**admissible**</font> for all states in that search space.\n",
    "\n",
    "<br>\n",
    "\n",
    "- To help remember whether it is \"never overestimates\" or \"never underestimates\", just remember that an **admissible heuristic is too optimistic**.  It will lead A\\* to search paths that turn out to be more costly that the optimal path.  It will not prevent  A\\*  from expanding a node that is on the optimal path by producing a heuristic $h$ value that is too high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Consistent Heuristic Function</center></h1>\n",
    "\n",
    "- A stronger requirement on a heuristic is that it is **consistent**, sometimes called **monotonic**.  A heuristic $h$ is consistent if its value is nondecreasing along a path. Mathematically, a heuristic $h$ is consistent if for every node $n$ of a parent node $p$,\n",
    "\n",
    "$$h(p) \\le h(n) + \\mathrm{stepcost}(p,n)$$\n",
    "\n",
    "- Every consistent heuristic must be admissible. One way of showing a heuristic is consistent is proving it is admissible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> <font color=\"blue\">Active Learning</font>: A* Search Exercise</center></h1>\n",
    "\n",
    ">Solve [this A* search problem](astarexercise.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Optimality of A*</center></h1>\n",
    "\n",
    "The tree-search version of A* is optimal if $h(n)$ is admissible, while the graph-version is optimal if $h(n)$ is consistent (mathematical proof in the textbook - but not required)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Memory-Bounded Heuristic Search</center></h1>\n",
    "\n",
    "- Iterative Deepening A* (IDA*) - uses f-cost, i.e. $(g+h)$ rather than the depth.\n",
    "\n",
    "\n",
    "- Recursive Best First Search (RBFS) - uses only linear space with a DFS strategy with a f-limit, once the limit is exceeded, it throws away nodes on that branch\n",
    "\n",
    "\n",
    "- Simplified MA* (SMA*) - like A-star expands the best leaf until memory is full, then drops the worst leaf node, also like RBFS backs up the value of the forgotten node to its parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<h1><center> Memory-Bounded Heuristic Search</center></h1>\n",
    "\n",
    "- No other algorithm that extends search paths from the start node and uses the same heuristic information will expand fewer nodes that A\\*.\n",
    "\n",
    "\n",
    "- However, maintaining the list of unexpanded frontier nodes can quickly consume all storage.  This is why we focus on the recursive-best-first-search **RBFS** version of A\\*.  Its iterative-deepening strategy  of throwing away and regenerating nodes reduces the maximum number of nodes stored at any point of the algorithm.  Its space complexity is linear in the depth of the deepest optimal solution. Its time complexity is hard to characterize as it depends on the accuracy of the heuristic function.\n",
    "\n",
    "\n",
    "- RBFS throws away too many nodes to be as efficient in time as it can be.  Alternatives include the simplified memory-bounded A\\*, <b>SMA\\*</b>, algorithm.  SMA\\* proceeds like a graph-based search maintaining the unexplored frontier list.  When it runs out of memory, it deletes the node with the worst $f$ value and backs that value up to the deleted node's parent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Summary of Chapter 3</center></h1>\n",
    "\n",
    "- Search environment characteristics: Observable, Known, Discrete, Deterministic\n",
    "\n",
    "- <font color=\"blue\">Uninfirmed Search</font>: BFS, Uniform-Cost Search, DFS, Depth-limited Search, Iterative Deepening Search, Bidirectional Search \n",
    "\n",
    "- <font color=\"blue\">Infirmed Search</font>: Greedy Best First Search, A* Search, IDA*, RBFS, SMA*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before we proceed to Chapter 4, watch this short video:\n",
    "https://www.linkedin.com/feed/update/urn:li:activity:6580049413157240833/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Chapter 4: Beyond Classical Search</center></h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Local Search</center></h1>\n",
    "\n",
    "<h5><center>Methods Inspired by Statistical Physics (Simulated Annealing) and Evolutionary Biology (Genetic Algorithms)</center></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Local Search</center></h1>\n",
    "\n",
    "- Local search algorithms operate using a single current node (rather than multiple paths), and generally move only to neighbors of that node.\n",
    "\n",
    "- Local serach algorithms are useful for solving <font color=\"blue\">optimization problems</font>, in which the im is to find the best state according to an <font color=\"blue\">objective function</font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Optimization Problems</center></h1>\n",
    "\n",
    "<img src=\"img/global-maximum.png\" align=\"center\"/>\n",
    "\n",
    "From Russel & Norvig Textbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Hill Climbing</center></h1>\n",
    "\n",
    "- Also known as Steepest ascent: This is our first example of a local search algorithm. Imagine you are climbing a mountain and you are in a very thick fog. You can only see a distance equal to one step length. To try to climb you take the step in the direction that is steepest to get to the highest point of all the locations you can currently see.\n",
    "\n",
    "\n",
    "- In other words, hill-climbing search simply evaluates the objective function for all states that are neighbors to the current state, and takes the neighbor state with the best objective function value as the new current state. If there are more than one next best states, one is picked randomly.\n",
    "\n",
    "\n",
    "- Hill-climbing search is sometimes called greedy search, because a step is taken after only considering the immediate neighbors. No time is spent considering possible future states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Hill Climbing</center></h1>\n",
    "\n",
    "Hill-climbing is easy to formulate and implement and often finds\n",
    "pretty good states quickly.  But, it has the following problems:\n",
    "\n",
    "  * it gets stuck on local optima (hills for maximizing searches, valleys for minimizing searches,\n",
    "  * it may get stuck on a ridge, if no single action can advance the search along the ridge,\n",
    "  * it may get stuck wandering on a plateau for which all neighboring states have equal value.\n",
    "\n",
    "Common variations include\n",
    "  * allow sideways moves (when on a plateau)\n",
    "  * stochastic hill-climbing: choose next state with probability related to increase in value of objective function\n",
    "  * first-choice hill-climbing: generate neighbors by random choice of available actions and keep first state that has better value,\n",
    "  * random-restart hill climbing: conduct multiple hill-climbing searches from multiple, randomly generated, initial states.\n",
    "\n",
    "Only this last one, with random-restarts, is **complete**.  In the limit, all states will be tried as starting states so the goal, or best state, will eventually be found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Simulated Annealing</center></h1>\n",
    "\n",
    "- Hill-climbing searches will get stuck on local optima.  Only by adding random restarts can you have a hill-climbing algorithm that is complete.\n",
    "\n",
    "\n",
    "- To get off of a local optimum, a search must be defined to allow steps that are \"downhill\" for maximizing searches, and \"uphill\" for minimizing searches, away from the optimum.  \n",
    "\n",
    "\n",
    "- [**Simulated annealing**]((https://www.mit.edu/~dbertsim/papers/Optimization/Simulated%20annealing.pdf)) is an algorithm that does this probabilisitically.  Assume we are doing a maximizing search, meaning we want to find the state with the maximum value.  Let the value of the current state be $v$.  Imagine an action has been applied to that state and the resulting state has a lower (worse) value $v'$.  Simulated annealing will accept this new state as the current state with probability $e^{(v' - v)/T}$.  $T$ is like a \"temperature\", the higher the value the more likely we are to take a step to a state with a worse value. In practice, $T$ starts at a high value and is slowly decreased towards zero.  If it is decreased \"slowly enough\", the global optimum will be found with probabilty 1.  In other words, this is a **complete** algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Simulated Annealing</center></h1>\n",
    "\n",
    "<img src=\"img/sa-1.jpg\" align=\"center\"/>\n",
    "\n",
    "Image from: https://rs.io/ultimate-guide-simulated-annealing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Simulated Annealing</center></h1>\n",
    "\n",
    "<img src=\"img/hc.jpg\" align=\"center\"/>\n",
    "\n",
    "Image from: https://rs.io/ultimate-guide-simulated-annealing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Simulated Annealing</center></h1>\n",
    "\n",
    "<img src=\"img/hc-fail.jpg\" align=\"center\"/>\n",
    "\n",
    "Image from: https://rs.io/ultimate-guide-simulated-annealing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center>Simulated Annealing</center></h1>\n",
    "\n",
    "<img src=\"img/sa-ping-pong.jpg\" align=\"center\"/>\n",
    "\n",
    "Image from: https://rs.io/ultimate-guide-simulated-annealing/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
